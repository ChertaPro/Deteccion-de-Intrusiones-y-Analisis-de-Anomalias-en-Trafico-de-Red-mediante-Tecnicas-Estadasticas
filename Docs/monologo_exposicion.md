# üé§ MON√ìLOGO PARA EXPOSICI√ìN (10-12 MINUTOS)

**Timing total:** 11 minutos | **Tono:** Profesional-acad√©mico, seguro, did√°ctico

---

## **[SLIDE 1 - PORTADA]** (30 seg)

*[Contacto visual con la audiencia, respirar profundo]*

Buenos d√≠as/tardes. Mi nombre es [TU NOMBRE] y hoy presentar√© mi proyecto de investigaci√≥n titulado **"Detecci√≥n de Intrusiones y An√°lisis de Anomal√≠as en Tr√°fico de Red mediante T√©cnicas Estad√≠sticas"**, realizado como trabajo final del curso de Estad√≠stica en MATCOM, Universidad de La Habana.

*[Pausa breve]*

La pregunta central que responderemos hoy es: **¬øPodemos detectar ataques de red sin conocerlos previamente?** Es decir, ¬øpueden las t√©cnicas estad√≠sticas identificar comportamientos maliciosos bas√°ndose √∫nicamente en patrones an√≥malos del tr√°fico, sin depender de cat√°logos de firmas?

*[Avanzar slide]*

---

## **[SLIDE 2 - CONTEXTO Y MOTIVACI√ìN]** (1 min 30 seg)

Para entender por qu√© este enfoque es relevante, primero veamos c√≥mo funcionan los **Sistemas de Detecci√≥n de Intrusiones tradicionales**.

Los IDS convencionales operan mediante **firmas conocidas** ‚Äì es como tener una base de datos de "huellas digitales" de ataques. Funcionan excelente contra amenazas catalogadas, **pero tienen un problema fundamental:** son **completamente ciegos ante ataques nuevos** ‚Äì los llamados "zero-day attacks".

*[Se√±alar segunda columna]*

Adem√°s, mantener estas bases de datos actualizadas es **costoso** y requiere actualizaci√≥n constante.

*[Pausa dram√°tica]*

**Nuestra propuesta** toma un camino diferente. En lugar de buscar firmas espec√≠ficas, buscamos **anomal√≠as estad√≠sticas** en el comportamiento del tr√°fico de red.

*[Se√±alar cuadro comparativo]*

Observen esta comparaci√≥n: mientras que la detecci√≥n por firmas **falla completamente** ante ataques nuevos o variantes, nuestro enfoque basado en anomal√≠as los **detecta porque su comportamiento estad√≠stico difiere del tr√°fico normal**, sin importar si los conocemos o no.

La ventaja clave es la **generalizaci√≥n**: aprendemos qu√© es "normal" y detectamos cualquier cosa que se desv√≠e significativamente.

*[Avanzar]*

---

## **[SLIDE 3 - DATASET NSL-KDD]** (1 min)

Para validar este enfoque, utilizamos el **dataset NSL-KDD**, que es el benchmark acad√©mico est√°ndar en investigaci√≥n de detecci√≥n de intrusiones.

NSL-KDD es una **versi√≥n mejorada** del cl√°sico KDD Cup 1999. Los investigadores del Canadian Institute for Cybersecurity eliminaron el 78% de registros redundantes que contaminaban el dataset original, haci√©ndolo mucho m√°s apropiado para entrenar modelos sin sobreajuste.

Trabajamos con:
- **25,192 observaciones de entrenamiento** (el subset estratificado del 20%)
- **22,544 observaciones de prueba**
- **41 variables** que describen el tr√°fico de red
- **5 categor√≠as:** Tr√°fico Normal (53.4%), ataques de Denegaci√≥n de Servicio o DoS (36.7%), Escaneo o Probe (9.1%), Acceso No Autorizado o R2L (0.8%), y Escalada de Privilegios o U2R (0.04%)

*[Se√±alar gr√°fico de barras]*

Noten el **desbalance severo**: U2R apenas representa 11 instancias en train, lo cual ser√° un desaf√≠o importante que veremos m√°s adelante.

*[Avanzar]*

---

## **[SLIDE 4 - VISUALIZACIONES]** (30 seg)

*[NOTA: Si esta slide tiene visualizaciones, describir brevemente. Si solo tiene t√≠tulo truncado, ser breve]*

Antes de aplicar t√©cnicas avanzadas, realizamos un **an√°lisis exploratorio exhaustivo** para entender la estructura de los datos.

Aqu√≠ vemos algunas distribuciones y patrones de outliers que nos ayudaron a formular nuestras hip√≥tesis.

*[Avanzar r√°pidamente - no detenerse mucho aqu√≠]*

---

## **[SLIDE 5 - EDA: HALLAZGOS CLAVE]** (1 min 30 seg)

El an√°lisis exploratorio revel√≥ tres hallazgos cr√≠ticos que guiaron nuestro enfoque metodol√≥gico:

**Primero, calidad de datos:** Excelente noticia ‚Äì **cero valores faltantes**. El dataset est√° completo. Sin embargo, detectamos que el **68.8% de las variables presentan asimetr√≠a extrema**, lo que viola los supuestos de normalidad. Esto nos obligar√° a usar **pruebas no param√©tricas** en lugar de ANOVA.

**Segundo, outliers:** Detectamos que el 18.6% de observaciones en la variable `dst_bytes` son outliers seg√∫n el criterio IQR de Tukey. *[Pausa]* Pero aqu√≠ viene lo interesante: **NO son ruido**. Al analizar su distribuci√≥n por categor√≠a, descubrimos que est√°n **concentrados en ataques**, no distribuidos aleatoriamente. Por ejemplo, en U2R, el 81.82% de instancias son outliers, versus solo 32.91% en tr√°fico Normal. Es decir, **los outliers son la se√±al que buscamos, no ruido a eliminar**.

**Tercero, multicolinealidad masiva:** Identificamos **14 pares de variables con correlaci√≥n mayor a 0.8**. Variables como `dst_host_srv_count` y `srv_count` miden esencialmente lo mismo. Esta redundancia motiva la necesidad de **reducci√≥n dimensional** que veremos en la Pregunta 2.

*[Avanzar]*

---

## **[SLIDE 6 - PREGUNTA 1: FIRMAS ESTAD√çSTICAS]** (1 min 45 seg)

Ahora s√≠, entramos en nuestras **tres preguntas de investigaci√≥n**.

**Pregunta 1:** *¬øTienen los ataques "firmas" estad√≠sticas distinguibles?*

Para responderla, seleccionamos 5 variables clave del tr√°fico ‚Äì `src_bytes`, `dst_bytes`, `duration`, `serror_rate` y `count` ‚Äì y aplicamos el **Test de Kruskal-Wallis**, que es la alternativa no param√©trica a ANOVA para comparar distribuciones entre m√∫ltiples grupos independientes.

Planteamos:
- **H‚ÇÄ:** Las distribuciones son id√©nticas entre las 5 categor√≠as
- **H‚ÇÅ:** Al menos una categor√≠a tiene distribuci√≥n diferente

*[Pausa dram√°tica]*

Los resultados son contundentes:

**Todas las variables** tienen **p-valor menor a 1√ó10‚Åª¬π‚Å∞** ‚Äì es decir, pr√°cticamente cero. La probabilidad de que estas diferencias sean casualidad es astron√≥micamente baja.

Adem√°s, el **tama√±o del efecto Epsilon-squared es mayor a 0.49** en todas, clasific√°ndose como **efecto GRANDE** seg√∫n los criterios de Cohen. Esto significa que las diferencias no solo son estad√≠sticamente significativas, sino **pr√°cticamente sustanciales**.

*[Se√±alar radar plot]*

Este radar plot visualiza los **perfiles estad√≠sticos** de cada categor√≠a usando las medianas normalizadas. Observen:

- **DoS** (en rojo) tiene un pico extremo en `serror_rate` y `count` ‚Äì esto es caracter√≠stico de ataques SYN flood masivos
- **U2R** (gris oscuro) destaca en `dst_bytes` y `duration` ‚Äì sesiones largas descargando exploits
- **Normal** (verde) tiene un perfil balanceado sin extremos

Cada pol√≠gono es claramente distinguible. **Conclusi√≥n de P1:** S√≠, cada tipo de ataque tiene una "huella digital" estad√≠stica robusta.

*[Avanzar]*

---

## **[SLIDE 7 - PATRONES ESPEC√çFICOS]** (1 min)

Esta slide detalla las **firmas espec√≠ficas** que identificamos:

**DoS (Denegaci√≥n de Servicio):**
- `src_bytes` y `dst_bytes` = 0 ‚Üí No hay transferencia de datos
- `serror_rate` = 1.0 ‚Üí 100% errores SYN
- `count` = 177 conexiones ‚Üí R√°faga masiva

Esto corresponde a un **SYN flood cl√°sico**: el atacante env√≠a miles de solicitudes SYN incompletas para colapsar el servidor.

**Probe (Escaneo de puertos):**
- `src_bytes` ‚âà 1 ‚Üí Paquetes m√≠nimos de sondeo
- `dst_bytes` = 0 ‚Üí No esperan respuesta completa
- Escanean r√°pidamente m√∫ltiples puertos buscando vulnerabilidades

**U2R (Escalada de privilegios):**
- `dst_bytes` = 3,860 ‚Üí Descarga de exploits o shells
- `duration` = 53 segundos ‚Üí Sesiones persistentes

**Normal:**
- Valores intermedios con **alta variabilidad** ‚Äì el uso leg√≠timo es naturalmente diverso

Estos patrones confirman que **el comportamiento an√≥malo deja huellas medibles**.

*[Avanzar]*

---

## **[SLIDE 8 - PREGUNTA 2: COMPRESI√ìN DIMENSIONAL]** (1 min 45 seg)

**Pregunta 2:** *¬øPodemos reducir las 32 variables sin perder informaci√≥n discriminante?*

Dado que detectamos multicolinealidad severa en el EDA, aplicamos **An√°lisis de Componentes Principales (PCA)** sobre las variables num√©ricas estandarizadas.

*[Se√±alar scree plot]*

El **scree plot** muestra la varianza explicada por cada componente. Buscamos el "codo" ‚Äì el punto donde los rendimientos decrecen abruptamente. Esto ocurre alrededor de los **5-6 componentes**.

Sin embargo, mediante **validaci√≥n cruzada**, determinamos que **8 componentes principales** ofrecen el mejor balance:
- Capturan el **71.85% de la varianza total**
- Logran una **reducci√≥n del 75%** en dimensionalidad (de 32 a 8 variables)
- Tienen **desempe√±o predictivo casi id√©ntico** a usar 13 PCs, pero con 38% menos features

*[Se√±alar proyecci√≥n 3D]*

Esta proyecci√≥n 3D visualiza los primeros 3 PCs. Aunque vemos cierta separaci√≥n, noten que el **Silhouette Score en 2D es solo 0.13** ‚Äì bastante bajo.

*[Pausa para √©nfasis]*

¬øEsto significa que PCA fall√≥? **No**. Al contrario, confirma que la separabilidad **NO est√° en proyecciones visuales simples**, sino en las **8 dimensiones combinadas** del espacio PCA. De hecho, como veremos en la siguiente pregunta, el AUC de 0.95 en 8D valida que capturamos la informaci√≥n discriminante esencial.

*[Avanzar]*

---

## **[SLIDE 9 - PREGUNTA 3: MODELOS PREDICTIVOS]** (1 min 30 seg)

**Pregunta 3:** *¬øPodemos predecir tipos espec√≠ficos de ataque usando componentes principales?*

Entrenamos **4 modelos de Regresi√≥n Log√≠stica binaria** con estrategia One-vs-Rest: cada modelo predice un tipo de ataque versus el resto.

Las features son los **8 componentes principales** obtenidos en P2.

*[Pausa]*

Los resultados son excelentes:
- **AUC promedio: 0.9496** ‚Äì clasificaci√≥n como "excelente" seg√∫n est√°ndares acad√©micos

Detallando por categor√≠a:
- **DoS: AUC 0.9902** ‚Äì pr√°cticamente perfecto
- **Probe: AUC 0.9868** ‚Äì tambi√©n excelente
- **R2L: AUC 0.9593** ‚Äì muy bueno, considerando el desbalance
- **U2R: AUC 0.8619** ‚Äì bueno, *notable dada la escasez extrema de datos* (solo 11 instancias)

*[Se√±alar curvas ROC]*

Estas curvas ROC visualizan el trade-off entre sensibilidad y especificidad. Todas est√°n muy por encima de la l√≠nea diagonal (clasificador aleatorio), confirmando poder discriminante robusto.

Adem√°s, validamos que **8 PCs vs 13 PCs** tienen desempe√±o casi id√©ntico (diferencia <0.5%), confirmando nuestra decisi√≥n de parsimonia.

*[Avanzar]*

---

## **[SLIDE 10 - DESEMPE√ëO DETALLADO]** (1 min)

*[Se√±alar tabla si es visible, sino referirse a texto]*

Analizando m√©tricas complementarias:

**Listos para producci√≥n:**
- DoS y Probe tienen **F1-Score mayor a 0.79**, indicando excelente balance entre precisi√≥n y recall. Estos modelos son **deployables** con m√≠nimo ajuste.

**Requieren ajustes:**
- R2L tiene AUC excelente (0.96) pero **F1 bajo (0.15)**. Esto es la **paradoja del desbalance**: el modelo discrimina bien (AUC alto), pero el threshold por defecto de 0.5 es inadecuado cuando la clase minoritaria es 0.8%. Ajustando el threshold seg√∫n el costo de falsos positivos/negativos, el F1 mejorar√≠a significativamente.

**Necesitan mejoras:**
- U2R con solo 11 instancias (0.04%) es el caso extremo. Incluso alcanzar AUC 0.86 con tan pocos ejemplos es notable. T√©cnicas de **oversampling como SMOTE** o simplemente conseguir m√°s datos mejorar√≠an sustancialmente la detecci√≥n.

*[Avanzar]*

---

## **[SLIDE 11 - COHERENCIA METODOL√ìGICA]** (1 min)

Esta es una de mis slides favoritas porque muestra la **coherencia metodol√≥gica** del estudio completo.

*[Se√±alar diagrama de flujo]*

Observen c√≥mo cada pregunta alimenta la siguiente:

**P1 - Kruskal-Wallis:**
- *Objetivo:* Identificar variables discriminantes
- *Resultado:* Œµ¬≤ > 0.5 en todas las variables clave
- *Salida:* 5 variables con alta separabilidad

**P2 - PCA:**
- *Objetivo:* Capturar esa informaci√≥n en componentes ortogonales
- *Resultado:* 8 PCs capturan 71.85% varianza
- *Salida:* Features comprimidas sin p√©rdida cr√≠tica

**P3 - Regresi√≥n Log√≠stica:**
- *Objetivo:* Explotar esos componentes para clasificaci√≥n
- *Resultado:* AUC = 0.9496 promedio
- *Salida:* Modelo predictivo viable y parsimonioso

*[Pausa]*

Las variables que mostraron mayor Epsilon-squared en P1 son precisamente las que tienen **loadings altos** en los componentes de P2, y esos componentes tienen **coeficientes altos** en los modelos de P3.

Es un flujo metodol√≥gico perfectamente coherente de hip√≥tesis a predicci√≥n.

*[Avanzar]*

---

## **[SLIDE 12 - CONCLUSIONES]** (1 min 30 seg)

Resumiendo, este estudio valida tres conclusiones fundamentales:

**CONCLUSI√ìN 1: Huellas Digitales Estad√≠sticas Robustas**

Los ataques de red **S√ç** presentan firmas estad√≠sticas distinguibles. Con p-valores menores a 1√ó10‚Åª¬π‚Å∞ y tama√±os de efecto Œµ¬≤ > 0.49, cada tipo de ataque tiene un perfil caracter√≠stico identificable.

**CONCLUSI√ìN 2: Compresi√≥n Dimensional Efectiva**

PCA logra reducir 75% la dimensionalidad preservando 71.85% de varianza sin p√©rdida de informaci√≥n cr√≠tica para clasificaci√≥n. La parsimonia es **viable y beneficiosa**.

**CONCLUSI√ìN 3: Modelos Predictivos Viables**

Regresi√≥n Log√≠stica con 8 PCs alcanza AUC = 0.9496, con DoS y Probe listos para producci√≥n, y R2L/U2R mejorables mediante t√©cnicas est√°ndar de balanceo.

*[Pausa dram√°tica, contacto visual con audiencia]*

**Conclusi√≥n final:**

El **an√°lisis estad√≠stico del comportamiento del tr√°fico de red** es un enfoque **complementario viable** a los IDS tradicionales. No lo reemplaza ‚Äì los sistemas de firmas siguen siendo excelentes para amenazas conocidas ‚Äì pero **complementa** su capacidad de detecci√≥n identificando anomal√≠as estad√≠sticas sin requerir conocimiento previo de ataques espec√≠ficos.

Este estudio demuestra que **"conocer lo normal"** puede ser tan valioso como **"conocer lo malicioso"**.

*[Avanzar]*

---

## **[SLIDE 13 - PREGUNTAS]** (30 seg)

Gracias por su atenci√≥n. Quedo a disposici√≥n para responder cualquier pregunta sobre la metodolog√≠a, resultados o implicaciones del estudio.

*[Sonre√≠r, contacto visual, brazos abiertos ‚Äì postura receptiva]*

---

# üéØ CONSEJOS DE DELIVERY

## **Timing por Secci√≥n:**
- Slides 1-3 (Intro + Dataset): 3 min
- Slides 4-5 (EDA): 2 min
- Slides 6-7 (P1): 2 min 45 seg
- Slide 8 (P2): 1 min 45 seg
- Slides 9-10 (P3): 2 min 30 seg
- Slides 11-12 (Coherencia + Conclusiones): 2 min 30 seg
- Slide 13 (Cierre): 30 seg
**TOTAL: 11 min 30 seg** ‚Üí Perfecto para 10-12 min con margen

## **Lenguaje Corporal:**
- **Contacto visual:** 70% del tiempo distribuido equitativamente
- **Gestos:** Se√±alar slides cuando digas "observen", "aqu√≠ vemos"
- **Pausas dram√°ticas:** Antes de resultados clave (p-valores, AUC)
- **Movimiento:** No est√°tico, pero tampoco inquieto
- **Postura:** Abierta, confiada, no cruzar brazos

## **Tono de Voz:**
- **Velocidad:** 130-150 palabras/min (ni lento ni acelerado)
- **Volumen:** Proyectar sin gritar
- **√ânfasis:** En palabras clave (cero valores faltantes, p<10‚Åª¬π‚Å∞, AUC 0.95)
- **Variaci√≥n:** No monoton√≠a ‚Äì modular para mantener atenci√≥n

## **Manejo de Preguntas:**
- **Escuchar completamente** antes de responder
- **Reformular** si no entendiste: "¬øMe pregunta si...?"
- **No bluffear:** Si no sabes, admitir honestamente
- **Conectar con el trabajo:** "Interesante pregunta, justo en la Slide X vimos..."

---

# üìù CHECKLIST PRE-EXPOSICI√ìN

- [ ] **Practicar 3 veces completas** con cron√≥metro
- [ ] **Corregir Slide 4** (t√≠tulo truncado)
- [ ] **Corregir Slide 8** (inconsistencia 5 vs 8 PCs)
- [ ] **Verificar Slide 10** (tabla legible)
- [ ] **Imprimir notas** en tarjetas peque√±as (bullet points clave)
- [ ] **Hidratar** antes (agua, no caf√© en exceso)
- [ ] **Llegar 10 min antes** para probar proyector/laptop
- [ ] **Respirar profundo** antes de empezar

---

¬°√âxito en tu exposici√≥n! üöÄ

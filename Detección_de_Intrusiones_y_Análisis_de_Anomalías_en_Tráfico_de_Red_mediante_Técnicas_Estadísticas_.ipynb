{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4292833",
   "metadata": {},
   "source": [
    "# Detecci√≥n de Intrusiones y An√°lisis de Anomal√≠as en Tr√°fico de Red mediante T√©cnicas Estad√≠sticas\n",
    "\n",
    "**Universidad de La Habana, MATCOM**  \n",
    "**Curso:** Estad√≠stica 2025-2026  \n",
    "**Proyecto Final:** An√°lisis Estad√≠stico Aplicado a Seguridad Inform√°tica\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3afbcff",
   "metadata": {},
   "source": [
    "## 1. Introducci√≥n al Proyecto\n",
    "\n",
    "### 1.1 Contexto y Motivaci√≥n\n",
    "\n",
    "La seguridad inform√°tica es uno de los pilares fundamentales en la infraestructura tecnol√≥gica moderna. Los Sistemas de Detecci√≥n de Intrusiones (IDS) tradicionales, basados en firmas conocidas, presentan limitaciones significativas frente a ataques emergentes o modificados (zero-day attacks). \n",
    "\n",
    "Este proyecto propone un enfoque complementario basado en **an√°lisis estad√≠stico del comportamiento del tr√°fico de red**, permitiendo identificar patrones an√≥malos sin depender exclusivamente de firmas previamente catalogadas. Este tipo de aproximaci√≥n resulta especialmente relevante en entornos din√°micos donde los ataques evolucionan constantemente.\n",
    "\n",
    "### 1.2 Objetivos del An√°lisis\n",
    "\n",
    "Este estudio busca responder **tres preguntas de investigaci√≥n fundamentales**:\n",
    "\n",
    "**Pregunta 1 (An√°lisis Comparativo):** ¬øExisten diferencias estad√≠sticamente significativas en el comportamiento de variables de flujo de red ‚Äîcomo `src_bytes`, `dst_bytes` y `duration`‚Äî entre el tr√°fico normal y los distintos tipos de ataques (DoS, Probe, R2L y U2R)?\n",
    "\n",
    "**Pregunta 2 (Reducci√≥n Dimensional):** ¬øEs posible reducir la dimensionalidad de las 41 caracter√≠sticas del tr√°fico de red mediante An√°lisis de Componentes Principales (PCA), conservando al menos el 95% de la varianza explicada, y c√≥mo impacta esta reducci√≥n en la visualizaci√≥n y separaci√≥n de los distintos tipos de ataques?\n",
    "\n",
    "**Pregunta 3 (Clasificaci√≥n Comparativa):** ¬øQu√© t√©cnica de clasificaci√≥n estad√≠stica, Regresi√≥n Log√≠stica o K-Vecinos m√°s Cercanos (K-NN), ofrece una mayor sensibilidad para detectar ataques raros (como U2R) en comparaci√≥n con ataques volum√©tricos m√°s comunes (como DoS)?\n",
    "\n",
    "### 1.3 Dataset: NSL-KDD\n",
    "\n",
    "**Fuente:** [NSL-KDD en Kaggle](https://www.kaggle.com/datasets/hassan06/nslkdd)\n",
    "\n",
    "El dataset NSL-KDD es una versi√≥n refinada del cl√°sico KDD Cup 1999, dise√±ada espec√≠ficamente para eliminar redundancias y sesgos presentes en el conjunto original. Es ampliamente reconocido como est√°ndar acad√©mico para la evaluaci√≥n de algoritmos de detecci√≥n de intrusiones.\n",
    "\n",
    "**Caracter√≠sticas principales:**\n",
    "- **41 variables predictoras** + 1 variable objetivo (`attack_type`) + 1 nivel de dificultad\n",
    "- **Tipos de ataques:** Normal, DoS (Denial of Service), Probe (escaneo/sondeo), R2L (Remote to Local), U2R (User to Root)\n",
    "- **Conjunto de entrenamiento:** 25,192 observaciones\n",
    "- **Conjunto de prueba:** 22,544 observaciones\n",
    "\n",
    "**Categorizaci√≥n de variables:**\n",
    "- **B√°sicas:** Derivadas de cabeceras TCP/IP (duration, protocol_type, src_bytes, dst_bytes, flag)\n",
    "- **De contenido:** Informaci√≥n sobre el payload (num_failed_logins, root_shell, etc.)\n",
    "- **De tr√°fico:** Estad√≠sticas temporales orientadas a detectar patrones (count, serror_rate, etc.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60a8ba5",
   "metadata": {},
   "source": [
    "## 1.4 Carga de Datos y Preparaci√≥n Inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab919d",
   "metadata": {},
   "source": [
    "# Imports y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cd5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥n de librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Configuraci√≥n de visualizaciones\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Estilo global para mantener consistencia en todas las visualizaciones\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 13\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "# Paleta de colores consistente para categor√≠as de ataque\n",
    "# Se utilizar√° en todas las visualizaciones del proyecto\n",
    "attack_colors = {\n",
    "    'Normal': '#2ecc71',    # Verde - Tr√°fico leg√≠timo\n",
    "    'DoS': '#e74c3c',       # Rojo - Ataques de denegaci√≥n de servicio\n",
    "    'Probe': '#f39c12',     # Naranja - Ataques de reconocimiento\n",
    "    'R2L': '#9b59b6',       # Morado - Acceso remoto no autorizado\n",
    "    'U2R': '#34495e'        # Gris oscuro - Escalada de privilegios\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas y configuraci√≥n de visualizaci√≥n establecida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534817e",
   "metadata": {},
   "source": [
    "## Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc41226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los nombres de las columnas (43 columnas en total)\n",
    "col_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\n",
    "    \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\",\n",
    "    \"num_failed_logins\", \"logged_in\", \"num_compromised\", \"root_shell\",\n",
    "    \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\",\n",
    "    \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
    "    \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\",\n",
    "    \"dst_host_srv_count\", \"dst_host_same_srv_rate\",\n",
    "    \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n",
    "    \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\",\n",
    "    \"dst_host_srv_rerror_rate\", \"attack_type\", \"difficulty_level\"\n",
    "]\n",
    "\n",
    "# Cargar los datasets\n",
    "# Nota: Ajusta las rutas seg√∫n tu estructura de carpetas\n",
    "train_df = pd.read_csv('Data/KDDTrain+_20Percent.txt', \n",
    "                       names=col_names, \n",
    "                       header=None)\n",
    "\n",
    "test_df = pd.read_csv('Data/KDDTest+.txt', \n",
    "                      names=col_names, \n",
    "                      header=None)\n",
    "\n",
    "# Crear variable binaria para clasificaci√≥n binaria (Normal vs. Ataque)\n",
    "train_df['is_attack'] = (train_df['attack_type'] != 'normal').astype(int)\n",
    "test_df['is_attack'] = (test_df['attack_type'] != 'normal').astype(int)\n",
    "\n",
    "# Mostrar informaci√≥n b√°sica\n",
    "print(f\"üìä Datos de entrenamiento: {train_df.shape}\")\n",
    "print(f\"üìä Datos de prueba: {test_df.shape}\")\n",
    "print(f\"\\n‚úÖ Datasets cargados exitosamente\")\n",
    "\n",
    "# Distribuci√≥n binaria inicial\n",
    "print(f\"\\nüéØ Distribuci√≥n binaria en entrenamiento (Normal vs. Ataque):\")\n",
    "print(train_df['is_attack'].value_counts(normalize=True).round(4))\n",
    "\n",
    "print(f\"\\nüéØ Distribuci√≥n binaria en prueba (Normal vs. Ataque):\")\n",
    "print(test_df['is_attack'].value_counts(normalize=True).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f34c121",
   "metadata": {},
   "source": [
    "## 1.5 Mapeo de Categor√≠as de Ataque\n",
    "\n",
    "El dataset NSL-KDD contiene 39 tipos de ataques espec√≠ficos que se agrupan en 4 categor√≠as principales m√°s la clase normal. A continuaci√≥n se realiza el mapeo oficial seg√∫n la documentaci√≥n del Canadian Institute for Cybersecurity:\n",
    "\n",
    "- **Normal:** Tr√°fico de red leg√≠timo\n",
    "- **DoS (Denial of Service):** Ataques que buscan denegar el servicio mediante sobrecarga de recursos\n",
    "- **Probe (Probing/Scanning):** Ataques de reconocimiento que escanean la red en busca de vulnerabilidades\n",
    "- **R2L (Remote to Local):** Intentos de acceso no autorizado desde una m√°quina remota\n",
    "- **U2R (User to Root):** Intentos de escalada de privilegios de usuario normal a superusuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1818a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario oficial de mapeo de ataques espec√≠ficos a categor√≠as generales\n",
    "# Fuente: Documentaci√≥n oficial NSL-KDD (Canadian Institute for Cybersecurity)\n",
    "attack_category_mapping = {\n",
    "    # Tr√°fico Normal\n",
    "    'normal': 'Normal',\n",
    "    \n",
    "    # DoS (Denial of Service) - Ataques de denegaci√≥n de servicio\n",
    "    'back': 'DoS', 'land': 'DoS', 'neptune': 'DoS', 'pod': 'DoS',\n",
    "    'smurf': 'DoS', 'teardrop': 'DoS', 'mailbomb': 'DoS', 'apache2': 'DoS',\n",
    "    'processtable': 'DoS', 'udpstorm': 'DoS',\n",
    "    \n",
    "    # Probe (Probing/Scanning) - Ataques de reconocimiento\n",
    "    'ipsweep': 'Probe', 'nmap': 'Probe', 'portsweep': 'Probe',\n",
    "    'satan': 'Probe', 'mscan': 'Probe', 'saint': 'Probe',\n",
    "    \n",
    "    # R2L (Remote to Local) - Acceso no autorizado desde m√°quina remota\n",
    "    'ftp_write': 'R2L', 'guess_passwd': 'R2L', 'imap': 'R2L',\n",
    "    'multihop': 'R2L', 'phf': 'R2L', 'spy': 'R2L',\n",
    "    'warezclient': 'R2L', 'warezmaster': 'R2L', 'sendmail': 'R2L',\n",
    "    'named': 'R2L', 'snmpgetattack': 'R2L', 'snmpguess': 'R2L',\n",
    "    'xlock': 'R2L', 'xsnoop': 'R2L', 'worm': 'R2L',\n",
    "    \n",
    "    # U2R (User to Root) - Escalada de privilegios\n",
    "    'buffer_overflow': 'U2R', 'loadmodule': 'U2R', 'perl': 'U2R',\n",
    "    'rootkit': 'U2R', 'httptunnel': 'U2R', 'ps': 'U2R', 'sqlattack': 'U2R'\n",
    "}\n",
    "\n",
    "# Aplicar mapeo a ambos datasets\n",
    "train_df['attack_category'] = train_df['attack_type'].map(attack_category_mapping)\n",
    "test_df['attack_category'] = test_df['attack_type'].map(attack_category_mapping)\n",
    "\n",
    "# Verificar que no hay valores sin mapear\n",
    "print(\"üîç Verificaci√≥n de mapeo de categor√≠as:\")\n",
    "unmapped_train = train_df['attack_category'].isna().sum()\n",
    "unmapped_test = test_df['attack_category'].isna().sum()\n",
    "print(f\"   Valores sin mapear en train: {unmapped_train}\")\n",
    "print(f\"   Valores sin mapear en test: {unmapped_test}\")\n",
    "\n",
    "if unmapped_test > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è ADVERTENCIA: Hay {unmapped_test} ataques en test sin categor√≠a asignada.\")\n",
    "    print(\"   Esto es esperado en NSL-KDD, que incluye ataques nuevos en el conjunto de prueba.\")\n",
    "    print(\"   Estos registros se filtrar√°n en an√°lisis posteriores.\")\n",
    "\n",
    "# Crear orden categ√≥rico para visualizaciones consistentes\n",
    "category_order = ['Normal', 'DoS', 'Probe', 'R2L', 'U2R']\n",
    "train_df['attack_category'] = pd.Categorical(\n",
    "    train_df['attack_category'], \n",
    "    categories=category_order, \n",
    "    ordered=True\n",
    ")\n",
    "test_df['attack_category'] = pd.Categorical(\n",
    "    test_df['attack_category'], \n",
    "    categories=category_order, \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Mostrar distribuci√≥n de categor√≠as\n",
    "print(\"\\nüìä Distribuci√≥n de categor√≠as en ENTRENAMIENTO:\")\n",
    "category_dist_train = train_df['attack_category'].value_counts()\n",
    "category_pct_train = train_df['attack_category'].value_counts(normalize=True) * 100\n",
    "category_summary_train = pd.DataFrame({\n",
    "    'Frecuencia': category_dist_train,\n",
    "    'Porcentaje': category_pct_train.round(2)\n",
    "})\n",
    "print(category_summary_train)\n",
    "\n",
    "print(\"\\nüìä Distribuci√≥n de categor√≠as en PRUEBA:\")\n",
    "category_dist_test = test_df[test_df['attack_category'].notna()]['attack_category'].value_counts()\n",
    "category_pct_test = test_df[test_df['attack_category'].notna()]['attack_category'].value_counts(normalize=True) * 100\n",
    "category_summary_test = pd.DataFrame({\n",
    "    'Frecuencia': category_dist_test,\n",
    "    'Porcentaje': category_pct_test.round(2)\n",
    "})\n",
    "print(category_summary_test)\n",
    "\n",
    "print(\"\\n‚úÖ Mapeo de categor√≠as completado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78856dd",
   "metadata": {},
   "source": [
    "## 1.6 Preparaci√≥n de Muestra Estratificada para Visualizaciones\n",
    "\n",
    "Para optimizar el rendimiento de visualizaciones complejas (como scatterplot matrices y pairplots), crearemos una muestra estratificada de 5,000 observaciones que mantenga las proporciones originales de cada categor√≠a de ataque. \n",
    "\n",
    "**Nota importante:** Esta muestra se utilizar√° **exclusivamente para visualizaciones**. Todos los an√°lisis estad√≠sticos (correlaciones, pruebas de hip√≥tesis, modelos) se realizar√°n sobre el dataset completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77858328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n del muestreo estratificado\n",
    "sample_size = 5000\n",
    "random_state = 42  # Para reproducibilidad\n",
    "\n",
    "# Crear muestra estratificada manteniendo proporciones de cada categor√≠a\n",
    "train_sample = train_df.groupby('attack_category', group_keys=False).apply(\n",
    "    lambda x: x.sample(\n",
    "        n=min(len(x), int(sample_size * len(x) / len(train_df))),\n",
    "        random_state=random_state\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(f\"üìä Muestra estratificada creada: {len(train_sample):,} observaciones\")\n",
    "print(f\"\\n‚úÖ Verificaci√≥n de estratificaci√≥n:\")\n",
    "\n",
    "# Comparar proporciones originales vs. muestra\n",
    "comparison = pd.DataFrame({\n",
    "    'Original (%)': train_df['attack_category'].value_counts(normalize=True).sort_index() * 100,\n",
    "    'Muestra (%)': train_sample['attack_category'].value_counts(normalize=True).sort_index() * 100\n",
    "})\n",
    "comparison['Diferencia (pp)'] = (comparison['Muestra (%)'] - comparison['Original (%)']).abs()\n",
    "print(comparison.round(2))\n",
    "\n",
    "print(\"\\nüí° Esta muestra se usar√° √∫nicamente para visualizaciones pesadas.\")\n",
    "print(\"   Los an√°lisis estad√≠sticos utilizar√°n el dataset completo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91279fc6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)\n",
    "\n",
    "El An√°lisis Exploratorio de Datos es fundamental para comprender la estructura, distribuci√≥n y relaciones presentes en el dataset antes de aplicar t√©cnicas estad√≠sticas avanzadas. Esta secci√≥n cumple tres objetivos principales:\n",
    "\n",
    "1. **Validar la calidad de los datos** y detectar problemas estructurales\n",
    "2. **Fundamentar decisiones de preparaci√≥n** que se implementar√°n en la secci√≥n 3\n",
    "3. **Generar hip√≥tesis preliminares** que guiar√°n las pruebas estad√≠sticas posteriores\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60456896",
   "metadata": {},
   "source": [
    "## 2.1 Informaci√≥n General del Dataset\n",
    "\n",
    "En esta primera secci√≥n del EDA realizaremos una exploraci√≥n estructural del dataset para verificar:\n",
    "- Dimensiones y tipos de datos\n",
    "- Presencia de valores nulos o faltantes\n",
    "- Distribuci√≥n de variables num√©ricas vs. categ√≥ricas\n",
    "- Uso de memoria, consideraciones computacionales y duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INFORMACI√ìN ESTRUCTURAL DEL DATASET\")\n",
    "\n",
    "# 1. Dimensiones\n",
    "print(f\"\\nüì¶ Dimensiones de los datasets:\")\n",
    "print(f\"   Entrenamiento: {train_df.shape[0]:,} observaciones √ó {train_df.shape[1]} variables\")\n",
    "print(f\"   Prueba: {test_df.shape[0]:,} observaciones √ó {test_df.shape[1]} variables\")\n",
    "\n",
    "# 2. Informaci√≥n de tipos de datos\n",
    "print(f\"\\nüî¢ Distribuci√≥n de tipos de datos (Train):\")\n",
    "print(train_df.dtypes.value_counts())\n",
    "\n",
    "# 3. Separaci√≥n de variables num√©ricas y categ√≥ricas\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Remover variables objetivo y auxiliares de las listas\n",
    "numeric_cols = [col for col in numeric_cols if col not in ['is_attack', 'difficulty_level']]\n",
    "categorical_cols = [col for col in categorical_cols if col not in ['attack_type', 'attack_category']]\n",
    "\n",
    "print(f\"\\nüìä Clasificaci√≥n de variables predictoras:\")\n",
    "print(f\"   Variables num√©ricas: {len(numeric_cols)}\")\n",
    "print(f\"   Variables categ√≥ricas: {len(categorical_cols)}\")\n",
    "print(f\"   Total de predictoras: {len(numeric_cols) + len(categorical_cols)}\")\n",
    "\n",
    "print(f\"\\n   Variables categ√≥ricas identificadas:\")\n",
    "for col in categorical_cols:\n",
    "    n_unique = train_df[col].nunique()\n",
    "    print(f\"      - {col}: {n_unique} categor√≠as √∫nicas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c378732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificaci√≥n de valores nulos en variables predictoras originales\n",
    "print(\"\\nüîç Verificaci√≥n de valores faltantes:\")\n",
    "\n",
    "# Excluir attack_category del an√°lisis de nulos (es variable derivada)\n",
    "original_cols = [col for col in train_df.columns if col not in ['attack_category', 'is_attack']]\n",
    "missing_train = train_df[original_cols].isnull().sum().sum()\n",
    "missing_test = test_df[original_cols].isnull().sum().sum()\n",
    "\n",
    "print(f\"   Dataset de entrenamiento: {missing_train} valores nulos\")\n",
    "print(f\"   Dataset de prueba: {missing_test} valores nulos\")\n",
    "\n",
    "if missing_train == 0 and missing_test == 0:\n",
    "    print(f\"\\n   ‚úÖ Excelente: No hay valores faltantes en las variables originales.\")\n",
    "    print(f\"      No se requiere imputaci√≥n de datos.\")\n",
    "else:\n",
    "    print(f\"\\n   ‚ö†Ô∏è Se detectaron valores faltantes. An√°lisis detallado:\")\n",
    "    if missing_train > 0:\n",
    "        print(f\"\\n   Columnas con valores nulos en TRAIN:\")\n",
    "        missing_cols_train = train_df[original_cols].isnull().sum()[train_df[original_cols].isnull().sum() > 0]\n",
    "        print(missing_cols_train)\n",
    "    if missing_test > 0:\n",
    "        print(f\"\\n   Columnas con valores nulos en TEST:\")\n",
    "        missing_cols_test = test_df[original_cols].isnull().sum()[test_df[original_cols].isnull().sum() > 0]\n",
    "        print(missing_cols_test)\n",
    "\n",
    "# Aclaraci√≥n sobre attack_category\n",
    "missing_attack_cat = test_df['attack_category'].isna().sum()\n",
    "if missing_attack_cat > 0:\n",
    "    print(f\"\\n   ‚ÑπÔ∏è Nota: {missing_attack_cat} observaciones en test no tienen 'attack_category' asignada.\")\n",
    "    print(f\"      Esto se debe a que contienen tipos de ataque nuevos no presentes en train.\")\n",
    "    print(f\"      Esta caracter√≠stica es intencional del dataset NSL-KDD para evaluar generalizaci√≥n.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc99cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de memoria y consideraciones computacionales\n",
    "print(\"\\nüíæ Uso de memoria:\")\n",
    "train_memory_mb = train_df.memory_usage(deep=True).sum() / 1024**2\n",
    "test_memory_mb = test_df.memory_usage(deep=True).sum() / 1024**2\n",
    "\n",
    "print(f\"   Dataset de entrenamiento: {train_memory_mb:.2f} MB\")\n",
    "print(f\"   Dataset de prueba: {test_memory_mb:.2f} MB\")\n",
    "print(f\"   Total en memoria: {train_memory_mb + test_memory_mb:.2f} MB\")\n",
    "\n",
    "if train_memory_mb + test_memory_mb < 100:\n",
    "    print(f\"\\n   ‚úÖ El dataset tiene un tama√±o manejable para an√°lisis completo.\")\n",
    "    print(f\"      No se requieren t√©cnicas especiales de optimizaci√≥n de memoria.\")\n",
    "else:\n",
    "    print(f\"\\n   ‚ö†Ô∏è Dataset de tama√±o considerable. Se recomienda:\")\n",
    "    print(f\"      - Usar muestras estratificadas para visualizaciones pesadas\")\n",
    "    print(f\"      - Monitorear uso de RAM durante an√°lisis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ba7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista previa de los datos\n",
    "print(\"\\nüìã Primeras 5 observaciones del dataset de entrenamiento:\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(\"\\nüìã √öltimas 5 observaciones del dataset de entrenamiento:\")\n",
    "display(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticos descriptivos de variables clave\n",
    "# Enfoc√°ndonos en las variables mencionadas en la Pregunta de Investigaci√≥n 1\n",
    "key_vars = ['duration', 'src_bytes', 'dst_bytes']\n",
    "\n",
    "print(\"\\nüìà Estad√≠sticos descriptivos de variables clave (Dataset completo):\")\n",
    "print(\"\\nEstas tres variables son centrales para la Pregunta de Investigaci√≥n 1.\")\n",
    "print(\"Se analizar√° si presentan diferencias significativas entre tr√°fico normal y ataques.\\n\")\n",
    "\n",
    "key_stats = train_df[key_vars].describe().T\n",
    "key_stats['range'] = key_stats['max'] - key_stats['min']\n",
    "key_stats['cv'] = (key_stats['std'] / key_stats['mean']) * 100  # Coeficiente de variaci√≥n\n",
    "\n",
    "display(key_stats[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'range', 'cv']])\n",
    "\n",
    "print(\"\\nüìä Interpretaci√≥n preliminar:\")\n",
    "for var in key_vars:\n",
    "    mean_val = train_df[var].mean()\n",
    "    median_val = train_df[var].median()\n",
    "    max_val = train_df[var].max()\n",
    "    cv = (train_df[var].std() / mean_val) * 100 if mean_val > 0 else 0\n",
    "    \n",
    "    print(f\"\\n   {var}:\")\n",
    "    print(f\"      - Rango: 0 a {max_val:,.0f}\")\n",
    "    print(f\"      - Media vs. Mediana: {mean_val:.2f} vs. {median_val:.2f}\")\n",
    "    \n",
    "    if median_val == 0:\n",
    "        print(f\"      - ‚ö†Ô∏è Mediana en 0: Indica que >50% de las conexiones tienen {var}=0\")\n",
    "    \n",
    "    if mean_val > median_val * 10 and median_val > 0:\n",
    "        print(f\"      - ‚ö†Ô∏è Asimetr√≠a positiva severa detectada (media >> mediana)\")\n",
    "        print(f\"      - Probable presencia de outliers extremos\")\n",
    "        print(f\"      - Recomendaci√≥n: Considerar transformaci√≥n logar√≠tmica para visualizaci√≥n\")\n",
    "    \n",
    "    if cv > 100:\n",
    "        print(f\"      - ‚ö†Ô∏è Coeficiente de variaci√≥n muy alto ({cv:.1f}%)\")\n",
    "        print(f\"      - Alta heterogeneidad en los datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ec6c2",
   "metadata": {},
   "source": [
    "### 2.1.1 Hallazgos de la Secci√≥n 2.1\n",
    "\n",
    "**Hallazgos estructurales:**\n",
    "\n",
    "1. **Calidad de datos:** No se detectaron valores nulos en las 43 variables originales del dataset (41 predictoras + attack_type + difficulty_level). La aparente ausencia de valores en `attack_category` del conjunto de prueba (13 casos) corresponde a tipos de ataque nuevos incluidos intencionalmente para evaluar generalizaci√≥n, no a valores faltantes reales.\n",
    "\n",
    "2. **Composici√≥n de variables:** \n",
    "   - **41 variables predictoras:** 38 num√©ricas (25 int64 + 13 float64) y 3 categ√≥ricas (protocol_type, service, flag)\n",
    "   - **Variables categ√≥ricas presentan diferentes cardinalidades:** protocol_type (3 categor√≠as), flag (11 categor√≠as), service (66 categor√≠as)\n",
    "   - Esta diversidad en cardinalidad requerir√° diferentes estrategias de codificaci√≥n en la preparaci√≥n de datos\n",
    "\n",
    "3. **Tama√±o computacionalmente manejable:** Con 24.33 MB de uso total de memoria (12.83 MB train + 11.50 MB test), el dataset completo puede procesarse en memoria sin necesidad de t√©cnicas de optimizaci√≥n especiales o procesamiento por lotes.\n",
    "\n",
    "**Observaciones sobre variables clave (duration, src_bytes, dst_bytes):**\n",
    "\n",
    "1. **Asimetr√≠a extrema y valores cero dominantes:**\n",
    "   - `duration` y `dst_bytes` tienen mediana = 0, indicando que m√°s del 50% de las conexiones presentan valor cero\n",
    "   - `src_bytes` tiene mediana de solo 44 bytes, mientras que su media es 24,330 bytes (553 veces mayor)\n",
    "   - Esta discrepancia media/mediana confirma distribuciones fuertemente sesgadas a la derecha\n",
    "\n",
    "2. **Heterogeneidad extrema:**\n",
    "   - Coeficientes de variaci√≥n extraordinariamente altos: duration (881%), src_bytes (9,909%), dst_bytes (2,544%)\n",
    "   - Valores superiores al 100% indican que la desviaci√≥n est√°ndar supera ampliamente la media\n",
    "   - Esta dispersi√≥n extrema es caracter√≠stica de datos de red que mezclan conexiones normales breves con ataques de gran volumen\n",
    "\n",
    "3. **Rangos de varios √≥rdenes de magnitud:**\n",
    "   - `src_bytes`: rango de 0 a 381 millones (9 √≥rdenes de magnitud)\n",
    "   - `dst_bytes`: rango de 0 a 5.1 millones\n",
    "   - `duration`: rango de 0 a 42,862 segundos (~12 horas)\n",
    "   - Estos rangos amplios sugieren presencia de outliers leg√≠timos (ataques masivos) que no deben eliminarse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
